{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(5, 4)\n",
    "w = np.random.randn(4, 3)\n",
    "b = np.ones((1, 3))\n",
    "\n",
    "t = np.zeros((5, 3))\n",
    "t[0, 0] = 1\n",
    "t[1, 0] = 1\n",
    "t[2, 1] = 1\n",
    "t[3, 1] = 1\n",
    "t[4, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19151945,  0.62210877,  0.43772774,  0.78535858],\n",
       "       [ 0.77997581,  0.27259261,  0.27646426,  0.80187218],\n",
       "       [ 0.95813935,  0.87593263,  0.35781727,  0.50099513],\n",
       "       [ 0.68346294,  0.71270203,  0.37025075,  0.56119619],\n",
       "       [ 0.50308317,  0.01376845,  0.77282662,  0.88264119]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32115819, -1.54690555, -0.20264632],\n",
       "       [-0.65596934,  0.19342138,  0.55343891],\n",
       "       [ 1.31815155, -0.46930528,  0.67555409],\n",
       "       [-1.81702723, -0.18310854,  1.05896919]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_model(inputs, weights, bias):\n",
    "    z = np.dot(x, w) + b\n",
    "    z = z - np.max(z, axis=1, keepdims=True) ## Safe softmax!\n",
    "    _e = np.exp(z)\n",
    "    logits = np.divide(_e, np.sum(_e, axis=1, keepdims=True))\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ce_loss(output, target):\n",
    "    return -1.0 * np.mean( np.sum(np.multiply(target, np.log(output)), axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = logistic_model(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.04161245474255"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss(output, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradients(logits, target, inputs):\n",
    "    assert logits.shape == target.shape\n",
    "    assert inputs.shape[0] == logits.shape[0]\n",
    "    \n",
    "    grad_z =  (logits - target) / (1.0 * target.shape[0])\n",
    "    grad_w = np.dot(inputs.T, grad_z)\n",
    "    grad_b = np.sum(grad_z, axis=0, keepdims=True)\n",
    "    \n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_w, eg_b = gradients(logistic_model(x, w, b), t, x)\n",
    "assert eg_w.shape == w.shape\n",
    "assert eg_b.shape == b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
